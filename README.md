**Project 1: Real-Time Hand Gesture Recognition (app.ipynb)**  

**Description:**  
This project is dedicated to real-time hand gesture recognition using the **MediaPipe** framework to detect and analyze hand landmarks. The system leverages webcam input to track hand movements and classify them into predefined gestures. **OpenCV** is used for image processing and visualization, while **TensorFlow** facilitates the use of pre-trained models for accurate gesture recognition.

**Key Features:**  
- **Real-Time Processing:** Uses **MediaPipe** to perform efficient and accurate hand landmark detection in real-time.  
- **Gesture Classification:** Identifies specific hand gestures by analyzing landmark positions and patterns.  
- **Integration with AI Models:** Implements a **TensorFlow** model for classification, ensuring high prediction accuracy.  
- **User-Friendly Interface:** Displays real-time visual feedback on the webcam feed to indicate recognized gestures.

**Technologies Used:**  
- **Python**  
- **OpenCV**  
- **MediaPipe**  
- **TensorFlow**  
- **NumPy**  

---

**Project 2: Gesture Image Collection for Training (gestures.ipynb)**  

**Description:**  
This project facilitates the creation and organization of a dataset comprising hand gesture images for training machine learning models. The system captures gesture images from a webcam and systematically sorts them into directories based on predefined categories. This dataset serves as an essential resource for developing gesture recognition models.

**Key Features:**  
- **Automated Dataset Generation:** Captures images from a webcam and stores them in corresponding directories based on gesture type.  
- **Custom Gesture Labels:** Supports a variety of predefined gestures, including 'Hello', 'Yes', 'No', 'Thank You', and others.  
- **Interactive Image Capture:** Enables users to control the image collection process through keyboard inputs for efficient dataset generation.  

**Technologies Used:**  
- **Python**  
- **OpenCV**  
- **NumPy**  
- **OS module**  

Additionally, a custom dataset was used to train both models, enhancing the accuracy and reliability of the gesture recognition system.

